---
title: "P8105 Homework 5"
author: "Kyung Suk Lee"
date: "`r Sys.Date()`"
output: 
  github_document:
    toc: yes
---

```{r load_packages, message = FALSE, warning = FALSE}
library(tidyverse)
library(rvest)

knitr::opts_chunk$set(
  fig.width = 6,
  fig.asp = .6,
  out.width = "90%")

theme_set(theme_minimal() + theme(legend.position = "bottom"))
options(
  ggplot2.continuous.colour = "viridis",
  ggplot2.continuous.fill = "viridis")

scale_colour_discrete = scale_color_viridis_d
scale_fill_discrete = scale_fill_viridis_d

knitr::opts_chunk$set(comment = NA, message = FALSE, warning = FALSE, echo = TRUE)
```

# Problem 1

## 1-1) Description of the raw data

```{r}
homicide_raw =
  read_csv("homicide_data/homicide-data.csv")
homicide_raw
```

* Some comments on raw data: This dataset is collected by The Washington Post by gathering data on more than 52,000 criminal homicides over the past decade in 50 of the largest American cities. The dataset is comprised of **`r homicide_raw %>% nrow()`** observations (rows) and **`r homicide_raw %>% ncol()`** columns. The variables include *`r homicide_raw %>% names()`*. Some of the important variables in this dataset are location of the killing, whether an arrest was made and, basic demographic information (e.g., sex, age, race) about each victim.

## 1-2) The number of homicides and unsolved homicides

```{r}
# create a city_state variable
# obtain the total number of homicides and the number of unsolved homicides
homicide_df = 
  homicide_raw %>% 
  janitor::clean_names() %>% 
  mutate(
    city_state = str_c(city, state, sep = ", "),
    resolved = case_when(
      disposition == "Closed without arrest" ~ "unsolved",
      disposition == "Open/No arrest"        ~ "unsolved",
      disposition == "Closed by arrest"      ~ "solved"
    )
  ) %>% 
  select(city_state, resolved) %>% 
  filter(city_state != "Tulsa, AL")

aggregate_df = 
  homicide_df %>% 
    group_by(city_state) %>% 
    summarize(
      hom_total = n(),
      hom_unsolved = sum(resolved == "unsolved")
      )

aggregate_df
```

## 1-3) Proportion of unsolved homicides (Baltimore)

```{r}
# pull the estimated proportion and confidence intervals

prop.test(
  aggregate_df %>% filter(city_state == "Baltimore, MD") %>% pull(hom_unsolved),
  aggregate_df %>% filter(city_state == "Baltimore, MD") %>% pull(hom_total)
  ) %>% 
  broom::tidy() %>% 
  select(estimate, conf.low, conf.high)
```

## 1-4) Proportion of unsolved homicides (All cities)

```{r}
# extract the proportion of unsolved homicides for each cities
# extract the confidence interval for each cities
results_df = 
  aggregate_df %>% 
    mutate(
      prop_tests = map2(.x = hom_unsolved, .y = hom_total, ~prop.test(x = .x, n = .y)),
      tidy_tests = map(.x = prop_tests, ~broom::tidy(.x))
    ) %>% 
    select(-prop_tests) %>% 
    unnest(tidy_tests) %>% 
    select(city_state, estimate, conf.low, conf.high)

results_df
```

## 1-5) Plot

```{r}
results_df %>%
  mutate(city_state = fct_reorder(city_state, estimate)) %>% 
  ggplot(aes(x = city_state, y = estimate, color = city_state)) +
  geom_point() +
  geom_errorbar(aes(ymin = conf.low, ymax = conf.high)) +
  labs(
      title = "Proportion of Unsolved Homicides",
      x = "City",
      y = "Proportion Estimates",
      caption = "Datasource: The Washington Post") +
  theme(legend.position = "none") +
  theme(axis.text.x = element_text(angle = 90, vjust = 0.5, hjust = 1)) +
  theme(plot.title = element_text(face="bold",
                                  hjust=0.5,
                                  lineheight=1.2))
```

# Problem 2

## 2-1) Create a tidy dataframe

```{r, eval = FALSE, error = TRUE}
data_1 = read_csv("arm_data/con_01.csv")

path_df = 
  tibble(
    path = list.files("lda_data")
  ) %>% 
  mutate(path = str_c("lda_data", path),
         data = map(...)
         )

read_csv(path_df$path[[1]])
```






